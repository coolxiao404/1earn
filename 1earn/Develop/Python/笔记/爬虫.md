# 爬虫

---

**爬虫的本质是什么？**

模拟浏览器打开网页，获取网页中我们想要的那部分数据

浏览器打开网页的过程： 当你在浏览器中输入地址后，经过 DNS 服务器找到服务器主机，向服务器发送一个请求，服务器经过解析后发送给用户浏览器结果，包括 html,js,css 等文件内容，浏览器解析出来最后呈现给用户在浏览器上看到的结果

所以用户看到的浏览器的结果就是由 HTML 代码构成的，我们爬虫就是为了获取这些内容，通过分析和过滤 html 代码，从中获取我们想要资源（文本，图片，视频.....）

**爬虫的基本流程**

- 发起请求

    通过HTTP库向目标站点发起请求，也就是发送一个 Request，请求可以包含额外的 header 等信息，等待服务器响应

- 获取响应内容

    如果服务器能正常响应，会得到一个 Response，Response 的内容便是所要获取的页面内容，类型可能是 HTML,Json 字符串，二进制数据（图片或者视频）等类型

- 解析内容

    得到的内容可能是 HTML,可以用正则表达式，页面解析库进行解析，可能是 Json,可以直接转换为 Json 对象解析，可能是二进制数据，可以做保存或者进一步的处理

- 保存数据

    保存形式多样，可以存为文本，也可以保存到数据库，或者保存特定格式的文件

**能爬取什么样的数据**

- 网页文本：如 HTML 文档，Json 格式化文本等
- 图片：获取到的是二进制文件，保存为图片格式
- 视频:同样是二进制文件
- 其他：只要请求到的，都可以获取

**如何解析数据**
- 直接处理
- Json 解析
- 正则表达式处理
- BeautifulSoup 解析处理
- PyQuery 解析处理
- XPath 解析处理

**关于抓取的页面数据和浏览器里看到的不一样的问题**

出现这种情况是因为，很多网站中的数据都是通过 js，ajax 动态加载的，所以直接通过 get 请求获取的页面和浏览器显示的不同。

**如何解决 js 渲染的问题？**
- 分析 ajax
- Selenium/webdriver
- Splash
- PyV8, Ghost.py

**怎样保存数据**
- 文本 ：纯文本，Json,Xml 等
- 关系型数据库 ：如 mysql,oracle,sql server 等结构化数据库
- 非关系型数据库 ：MongoDB,Redis 等 key-value 形式存储

---

# Scrapy

- https://github.com/scrapy/scrapy

Scrapy 是一套基于基于 Twisted 的异步处理框架，纯 python 实现的爬虫框架，用户只需要定制开发几个模块就可以轻松的实现一个爬虫，用来抓取网页内容以及各种图片，非常之方便

**安装**
```bash
pip install scrapy
```

**示例代码**
```python
import scrapy

class BlogSpider(scrapy.Spider):
    name = 'blogspider'
    start_urls = ['https://blog.scrapinghub.com']

    def parse(self, response):
        for title in response.css('h2.entry-title'):
            yield {'title': title.css('a ::text').extract_first()}

        next_page = response.css('div.prev-post > a ::attr(href)').extract_first()
        if next_page:
            yield scrapy.Request(response.urljoin(next_page), callback=self.parse)
```

**运行**
```bash
scrapy runspider spider.py
```
